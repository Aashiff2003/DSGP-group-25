{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1q02N632V1P8E-V32Uf0ybA5A36VOYtmn","authorship_tag":"ABX9TyOfz9UcSNsr8FyxUzzvlGSV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n","from tensorflow.keras.applications import MobileNetV2\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","drive_path='/content/drive/Mydrive/'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FF7ynoDrmV37","executionInfo":{"status":"ok","timestamp":1733549465300,"user_tz":-330,"elapsed":3733,"user":{"displayName":"Akshan Kumarasan","userId":"16742592844346683021"}},"outputId":"0dca207b-604d-4530-e1a4-430fed69f625"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","\n","# Define paths\n","base_dir = '/content/drive/MyDrive/dataset'\n","csv_path = os.path.join(base_dir, 'test.csv')  # Adjust if your CSV file is named differently\n","image_dir = base_dir  # Images are inside the subfolders of `dataset`\n","\n","# Load CSV file\n","df = pd.read_csv(csv_path)\n","\n","# Map image paths to full paths\n","df['image_path'] = df['Image_id'].apply(lambda x: os.path.join(image_dir, x))\n","df = df[df['image_path'].apply(lambda x: os.path.exists(x))]  # Filter rows where images exist\n","\n","# Check data\n","print(f\"Number of images in dataset: {len(df)}\")\n","print(df.head())\n","\n","# Split the dataset into training and validation sets\n","from sklearn.model_selection import train_test_split\n","train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['labels'], random_state=42)\n","\n","# Define parameters for image processing\n","img_height, img_width = 224, 224\n","batch_size = 32\n","\n","# Use ImageDataGenerator to load and augment images\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0/255,\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","val_datagen = ImageDataGenerator(rescale=1.0/255)\n","\n","# Create training and validation generators\n","train_generator = train_datagen.flow_from_dataframe(\n","    train_df,\n","    x_col='image_path',\n","    y_col='labels',\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","val_generator = val_datagen.flow_from_dataframe(\n","    val_df,\n","    x_col='image_path',\n","    y_col='labels',\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","# Verify the class indices\n","print(\"Class Indices:\", train_generator.class_indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"aO3gR_PGmamH","executionInfo":{"status":"error","timestamp":1733549602689,"user_tz":-330,"elapsed":864,"user":{"displayName":"Akshan Kumarasan","userId":"16742592844346683021"}},"outputId":"3162f521-c451-484f-c07a-08b9b984894f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images in dataset: 0\n","Empty DataFrame\n","Columns: [Image_id, labels, image_path]\n","Index: []\n"]},{"output_type":"error","ename":"ValueError","evalue":"With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-a5d3500ba67a>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Split the dataset into training and validation sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Define parameters for image processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2785\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2786\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2787\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2416\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."]}]},{"cell_type":"code","source":["\n","\n","# Define the dataset path\n","base_dir = '/content/drive/MyDrive/dataset'  # Replace with the actual dataset folder path\n","\n","# Define parameters for image processing\n","img_height, img_width = 224, 224  # Image size for input\n","batch_size = 32\n","\n","# Use ImageDataGenerator to load and augment images\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0/255,          # Normalize pixel values to [0, 1]\n","    rotation_range=30,        # Randomly rotate images\n","    width_shift_range=0.2,    # Shift images horizontally\n","    height_shift_range=0.2,   # Shift images vertically\n","    shear_range=0.2,          # Apply shear transformation\n","    zoom_range=0.2,           # Apply zoom\n","    horizontal_flip=True,     # Flip images horizontally\n","    validation_split=0.2      # Use 20% of the data for validation\n",")\n","\n","# Create training and validation generators\n","train_generator = train_datagen.flow_from_directory(\n","    base_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='training'  # Use training subset\n",")\n","\n","val_generator = train_datagen.flow_from_directory(\n","    base_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='validation'  # Use validation subset\n",")\n","\n","# Verify class indices\n","print(\"Class Indices:\", train_generator.class_indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mui4i-nxnYyl","executionInfo":{"status":"ok","timestamp":1733549734314,"user_tz":-330,"elapsed":447,"user":{"displayName":"Akshan Kumarasan","userId":"16742592844346683021"}},"outputId":"9278ac06-8b9b-4a97-8716-aa1283e1f847"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1224 images belonging to 6 classes.\n","Found 306 images belonging to 6 classes.\n","Class Indices: {'alien_test': 0, 'cloudy': 1, 'foggy': 2, 'rainy': 3, 'shine': 4, 'sunrise': 5}\n"]}]},{"cell_type":"code","source":["# Model definition\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","model = Sequential([\n","    Input(shape=(224, 224, 3)),\n","    Conv2D(32, (3, 3), activation='relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(6, activation='softmax')  # 6 classes\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Calculate steps per epoch\n","steps_per_epoch = train_generator.samples // train_generator.batch_size\n","validation_steps = val_generator.samples // val_generator.batch_size\n","\n","# Train the model\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","history = model.fit(\n","    train_generator,\n","    validation_data=val_generator,\n","    epochs=20,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_steps=validation_steps,\n","    callbacks=[early_stopping]\n",")\n","\n","# Save the model\n","model.save('weather_classification_model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nPRPiOXTngmA","executionInfo":{"status":"ok","timestamp":1733551864260,"user_tz":-330,"elapsed":1437092,"user":{"displayName":"Akshan Kumarasan","userId":"16742592844346683021"}},"outputId":"d6486d79-e44a-4482-853e-5173f68ce02f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 5s/step - accuracy: 0.3835 - loss: 1.9960 - val_accuracy: 0.5938 - val_loss: 1.1751\n","Epoch 2/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4375 - loss: 1.4007 - val_accuracy: 0.5000 - val_loss: 1.1948\n","Epoch 3/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 5s/step - accuracy: 0.5808 - loss: 1.1320 - val_accuracy: 0.5903 - val_loss: 1.1002\n","Epoch 4/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7812 - loss: 0.8128 - val_accuracy: 0.7222 - val_loss: 1.0157\n","Epoch 5/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 5s/step - accuracy: 0.6732 - loss: 0.9335 - val_accuracy: 0.5729 - val_loss: 1.3135\n","Epoch 6/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.6562 - loss: 1.0239 - val_accuracy: 0.5556 - val_loss: 1.1560\n","Epoch 7/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 5s/step - accuracy: 0.6706 - loss: 0.9236 - val_accuracy: 0.6736 - val_loss: 0.9193\n","Epoch 8/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.5312 - loss: 1.2256 - val_accuracy: 0.7778 - val_loss: 0.6686\n","Epoch 9/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 5s/step - accuracy: 0.7304 - loss: 0.8066 - val_accuracy: 0.7153 - val_loss: 0.9519\n","Epoch 10/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8750 - loss: 0.6171 - val_accuracy: 0.7222 - val_loss: 0.7592\n","Epoch 11/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 5s/step - accuracy: 0.7256 - loss: 0.7762 - val_accuracy: 0.7083 - val_loss: 0.8423\n","Epoch 12/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6562 - loss: 0.9284 - val_accuracy: 0.6667 - val_loss: 1.0544\n","Epoch 13/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 5s/step - accuracy: 0.7253 - loss: 0.7998 - val_accuracy: 0.7049 - val_loss: 0.8873\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]},{"cell_type":"code","source":["# Save the model\n","model.save('weather_classification_model.keras')"],"metadata":{"id":"4BJNfoPiv_GS"},"execution_count":null,"outputs":[]}]}